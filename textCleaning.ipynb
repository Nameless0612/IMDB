{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef5ffdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "301fbec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e833b9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\marqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\marqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\marqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\", quiet=False, force=True)\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5a24817",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = string.punctuation\n",
    "stopWords = nltk.corpus.stopwords.words('english')\n",
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbf7fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCleanText(text):\n",
    "    onlyText = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    textNoPunctNLow = \"\".join([char.lower() for char in onlyText if char not in punctuation]) \n",
    "    tokens = word_tokenize(textNoPunctNLow)\n",
    "    finalText = \" \".join(lm.lemmatize(word) for word in tokens if word not in stopWords)\n",
    "    return finalText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da140d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wonderful little production filming technique unassuming oldtimebbc fashion give comforting sometimes discomforting sense realism entire piece actor extremely well chosen michael sheen got polari voice pat truly see seamless editing guided reference williams diary entry well worth watching terrificly written performed piece masterful production one great master comedy life realism really come home little thing fantasy guard rather use traditional dream technique remains solid disappears play knowledge sens particularly scene concerning orton halliwell set particularly flat halliwells mural decorating every surface terribly well done'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetCleanText(raw_data['review'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3291a8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one reviewer mentioned watching 1 oz episode y...\n",
       "1        wonderful little production filming technique ...\n",
       "2        thought wonderful way spend time hot summer we...\n",
       "3        basically there family little boy jake think t...\n",
       "4        petter matteis love time money visually stunni...\n",
       "                               ...                        \n",
       "49995    thought movie right good job wasnt creative or...\n",
       "49996    bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    catholic taught parochial elementary school nu...\n",
       "49998    im going disagree previous comment side maltin...\n",
       "49999    one expects star trek movie high art fan expec...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = raw_data['review'].apply(lambda x: GetCleanText(x))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc13106e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "49995    1\n",
       "49996    0\n",
       "49997    0\n",
       "49998    0\n",
       "49999    0\n",
       "Name: sentiment, Length: 50000, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = raw_data['sentiment'].apply(lambda x: 1 if x=='positive' else 0)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb9c0fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c584e",
   "metadata": {},
   "source": [
    "## Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d68a9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05ab635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabSize = 20000\n",
    "maxLen = 200\n",
    "vectorizeLayer = TextVectorization(\n",
    "    max_tokens = vocabSize,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = maxLen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5932336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building vocabulary since there's non in the dataset\n",
    "vectorizeLayer.adapt(X_train)\n",
    "\n",
    "vectorizedTrainingSet = vectorizeLayer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5d46f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movie came went theater due nature see wasnt well received unfairly panned subject matter actual film higher learning spectacular good film tried talk feared subject america racismplotstory higher learning mostly centered around malikplayed omar epps naive track star deal fast enough stern professorplayed laurence fishburne befriends fudgeice cube well gorgeous lady named dejatyra bank later end deal skinhead campus remyplay michael rapaport confused kid end befriending local skinhead campus impose view becomes racist areopinion higher learning without flaw character development scarce okay performance omar epps tyra bank leader skinheadswhose name forgot busta rhyme doesnt fit movie plus woman turning gay abused men clich√© film know didnt like part film kristy swanson movie wasnt half bad laurence fishburne good professor phippseven though could without accent fudge ice cube best performance michael rapaport good confused remy one john singleton best movie one one reason frown rubbish put cinema need movie like higher learning mississippi burning american history x less movie like baby boy 2 fast 2 furious pointless remake shaft'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.to_list()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "624e0b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200,), dtype=int64, numpy=\n",
       "array([    2,   276,   307,   501,   551,   809,    14,   192,    18,\n",
       "        1795, 10041,  9284,   576,   340,   656,     3,  1745,  2587,\n",
       "        1903,     7,     3,   644,   452,  7941,   576,   724,     1,\n",
       "        1745,  2587,   541,  5124,    99,     1,  7509, 10125,  2356,\n",
       "         979,   108,   482,   746,   101,  7055,     1,  5543,  7172,\n",
       "        5127,     1,  4577,    18,  1399,   479,   651,     1,  1656,\n",
       "         212,    45,   482, 19678,  5565,     1,   382, 18937,  1294,\n",
       "         133,    45,     1,   508, 19678,  5565, 14418,   457,   358,\n",
       "        2637,     1,  1745,  2587,   115,  1002,     8,   791, 15164,\n",
       "         727,    70,  7509, 10125, 10976,  1656,  1373,     1,   226,\n",
       "        2323,     1,  6405,    67,   693,     2,   798,    72,  1462,\n",
       "         714,  4557,   244,  1503,     3,    33,    69,     5,    56,\n",
       "           3, 14847,  7777,     2,   192,   253,    21,  5543,  7172,\n",
       "           7,  2023,     1,    73,    30,   115,   776, 17046,  1980,\n",
       "        4577,    46,    70,   382, 18937,     7,  1294,     1,     4,\n",
       "         213, 13190,    46,     2,     4,     4,   146, 18417,  1809,\n",
       "         147,   329,   164,     2,     5,  1745,  2587, 11274,  3183,\n",
       "         175,   394,  2706,   252,     2,     5,   743,   207,   209,\n",
       "         746,   209,  5381,  1014,   801,  8478,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0], dtype=int64)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizedTrainingSet[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eae478a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tens_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
