{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef5ffdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "301fbec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e833b9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\marqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\marqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\marqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\", quiet=False, force=True)\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5a24817",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = string.punctuation\n",
    "stopWords = nltk.corpus.stopwords.words('english')\n",
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbf7fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCleanText(text):\n",
    "    onlyText = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    textNoPunctNLow = \"\".join([char.lower() for char in onlyText if char not in punctuation]) \n",
    "    tokens = word_tokenize(textNoPunctNLow)\n",
    "    finalText = \" \".join(lm.lemmatize(word) for word in tokens if word not in stopWords)\n",
    "    return finalText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da140d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wonderful little production filming technique unassuming oldtimebbc fashion give comforting sometimes discomforting sense realism entire piece actor extremely well chosen michael sheen got polari voice pat truly see seamless editing guided reference williams diary entry well worth watching terrificly written performed piece masterful production one great master comedy life realism really come home little thing fantasy guard rather use traditional dream technique remains solid disappears play knowledge sens particularly scene concerning orton halliwell set particularly flat halliwells mural decorating every surface terribly well done'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetCleanText(raw_data['review'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3291a8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one reviewer mentioned watching 1 oz episode y...\n",
       "1        wonderful little production filming technique ...\n",
       "2        thought wonderful way spend time hot summer we...\n",
       "3        basically there family little boy jake think t...\n",
       "4        petter matteis love time money visually stunni...\n",
       "                               ...                        \n",
       "49995    thought movie right good job wasnt creative or...\n",
       "49996    bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    catholic taught parochial elementary school nu...\n",
       "49998    im going disagree previous comment side maltin...\n",
       "49999    one expects star trek movie high art fan expec...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = raw_data['review'].apply(lambda x: GetCleanText(x))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc13106e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "49995    1\n",
       "49996    0\n",
       "49997    0\n",
       "49998    0\n",
       "49999    0\n",
       "Name: sentiment, Length: 50000, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = raw_data['sentiment'].apply(lambda x: 1 if x=='positive' else 0)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb9c0fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c584e",
   "metadata": {},
   "source": [
    "## Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d68a9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05ab635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabSize = 20000\n",
    "maxLen = 200\n",
    "vectorizeLayer = TextVectorization(\n",
    "    max_tokens = vocabSize,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = maxLen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5932336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building vocabulary since there's non in the dataset\n",
    "vectorizeLayer.adapt(X_train)\n",
    "\n",
    "vectorizedTrainingSet = vectorizeLayer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5d46f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first thing first movie achingly beautiful someone work 3d cg film lightercompositor visuals blew away every second stunned screen story well okay going set world fire like futuristic blade runneresquire tale doesnt finei say felt voice acting particularly bland detracted movie whole saw cinema english hoping french version floating around somewheredefinitely worth seeing'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.to_list()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "624e0b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200,), dtype=int64, numpy=\n",
       "array([   23,    27,    23,     2, 13480,   211,   179,    55,  3949,\n",
       "        4310,     3,     1,  1866,  3729,   154,    82,   204,  4572,\n",
       "         187,    11,    18,   726,    77,   128,    89,   761,     5,\n",
       "        4140,  2812,     1,   576,    68,     1,    40,   325,   405,\n",
       "          44,   472,  1757, 14560,     2,   129,   116,   332,   521,\n",
       "        1206,   584,   196,  3909,    96,     1,   184,   213,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0], dtype=int64)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizedTrainingSet[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8eae478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embed = Embedding(\n",
    "    input_dim = vocabSize,\n",
    "    output_dim = 100,\n",
    "    \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7456ee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200,), dtype=int64, numpy=\n",
       "array([   23,    27,    23,     2, 13480,   211,   179,    55,  3949,\n",
       "        4310,     3,     1,  1866,  3729,   154,    82,   204,  4572,\n",
       "         187,    11,    18,   726,    77,   128,    89,   761,     5,\n",
       "        4140,  2812,     1,   576,    68,     1,    40,   325,   405,\n",
       "          44,   472,  1757, 14560,     2,   129,   116,   332,   521,\n",
       "        1206,   584,   196,  3909,    96,     1,   184,   213,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0], dtype=int64)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizedTrainingSet[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "165a51fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200, 100), dtype=float32, numpy=\n",
       "array([[-0.01717552,  0.03517122, -0.0231637 , ..., -0.02296155,\n",
       "         0.01240039, -0.02624132],\n",
       "       [-0.01822238, -0.0128541 ,  0.04156313, ..., -0.02275989,\n",
       "         0.0179451 , -0.02814208],\n",
       "       [-0.01717552,  0.03517122, -0.0231637 , ..., -0.02296155,\n",
       "         0.01240039, -0.02624132],\n",
       "       ...,\n",
       "       [ 0.01921555,  0.03018453,  0.00447141, ...,  0.01050133,\n",
       "        -0.0328871 , -0.03372177],\n",
       "       [ 0.01921555,  0.03018453,  0.00447141, ...,  0.01050133,\n",
       "        -0.0328871 , -0.03372177],\n",
       "       [ 0.01921555,  0.03018453,  0.00447141, ...,  0.01050133,\n",
       "        -0.0328871 , -0.03372177]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(vectorizedTrainingSet[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8aed2918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.preprocessing.text_vectorization.TextVectorization at 0x1ecf0cda350>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizeLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "286976db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01381447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_4 (TextV  (None, 200)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 200, 100)          2000000   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                6464      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,086,929\n",
      "Trainable params: 2,086,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(1,), dtype=tf.string))\n",
    "model.add(vectorizeLayer)\n",
    "model.add(embed)\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c0e383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8095ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tens_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
